<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>delta.imagery.imagery_dataset API documentation</title>
<meta name="description" content="Tools for loading input images into the TensorFlow Dataset class." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>delta.imagery.imagery_dataset</code></h1>
</header>
<section id="section-intro">
<p>Tools for loading input images into the TensorFlow Dataset class.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># Copyright Â© 2020, United States Government, as represented by the
# Administrator of the National Aeronautics and Space Administration.
# All rights reserved.
#
# The DELTA (Deep Earth Learning, Tools, and Analysis) platform is
# licensed under the Apache License, Version 2.0 (the &#34;License&#34;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &#34;AS IS&#34; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

&#34;&#34;&#34;
Tools for loading input images into the TensorFlow Dataset class.
&#34;&#34;&#34;
from concurrent.futures import ThreadPoolExecutor
import functools
import random
import threading
import tensorflow as tf
import numpy as np

from delta.imagery import rectangle
from delta.config import config

class ImageryDataset: # pylint: disable=too-many-instance-attributes,too-many-arguments
    &#34;&#34;&#34;
    A dataset for tiling very large imagery for training with tensorflow.
    &#34;&#34;&#34;

    def __init__(self, images, labels, output_shape, chunk_shape, stride=None,
                 tile_shape=(256, 256), tile_overlap=None, max_rand_offset=None):
        &#34;&#34;&#34;
        Parameters
        ----------
        images: ImageSet
            Images to train on
        labels: ImageSet
            Corresponding labels to train on
        output_shape: (int, int)
            Shape of the corresponding labels for a given chunk or tile size.
        chunk_shape: (int, int)
            If specified, divide tiles into individual chunks of this shape.
        stride: (int, int)
            Skip this stride between chunks. Only valid with chunk_shape.
        tile_shape: (int, int)
            Size of tiles to load from the images at a time.
        tile_overlap: (int, int)
            If specified, overlap tiles by this amount.
        max_rand_offset: int
            If specified, in each epoch, offset all tiles by a random amount in x and y
            in the range(-max_rand_offset, max_rand_offset).
        &#34;&#34;&#34;

        self._iopool = ThreadPoolExecutor(config.io.threads())

        # Record some of the config values
        self.set_chunk_output_shapes(chunk_shape, output_shape)
        self._output_dims  = 1
        # one for imagery, one for labels
        if stride is None:
            stride = (1, 1)
        self._stride = stride
        self._data_type    = tf.float32
        self._label_type   = tf.uint8
        self._tile_shape = tile_shape
        if tile_overlap is None:
            tile_overlap = (0, 0)
        self._tile_overlap = tile_overlap
        self._max_rand_offset = max_rand_offset if max_rand_offset else 0

        if labels:
            assert len(images) == len(labels)
        self._images = images
        self._labels = labels
        self._epoch = [0, 0] # track images and labels separately for simplicity

        # Load the first image to get the number of bands for the input files.
        self._num_bands = images.load(0).num_bands()
        self._random_seed = random.randint(0, 1 &lt;&lt; 16)

    def _list_tiles(self, i): # pragma: no cover
        &#34;&#34;&#34;
        Parameters
        ----------
        i: int
            Image to list tiles for.

        Returns
        -------
        List[Rectangle]:
            List of tiles to read from the given image
        &#34;&#34;&#34;
        img = self._images.load(i)

        if self._labels: # If we have labels make sure they are the same size as the input images
            label = self._labels.load(i)
            if label.size() != img.size():
                raise AssertionError(&#39;Label file &#39; + self._labels[i] + &#39; with size &#39; + str(label.size())
                                     + &#39; does not match input image &#39; + self._images[i] + &#39; size of &#39; + str(img.size()))
        tile_shape = self._tile_shape
        if self._chunk_shape:
            assert tile_shape[0] &gt;= self._chunk_shape[0] and \
                   tile_shape[1] &gt;= self._chunk_shape[1], &#39;Tile too small.&#39;
            return img.tiles((tile_shape[0], tile_shape[1]), min_shape=self._chunk_shape,
                             overlap_shape=self._tile_overlap,
                             by_block=True)
        return img.tiles((tile_shape[0], tile_shape[1]), partials=False, partials_overlap=True,
                         overlap_shape=self._tile_overlap, by_block=True)

    def _tile_generator(self, is_labels): # pragma: no cover
        &#34;&#34;&#34;
        A generator that yields image tiles over all images.

        Parameters
        ----------
        is_labels: bool
            Load the label if true, image if false

        Returns
        -------
        Iterator[numpy.ndarray]:
            Iterator over iamge tiles.
        &#34;&#34;&#34;
        # track epoch (must be same for label and non-label)
        epoch = self._epoch[1 if is_labels else 0]
        self._epoch[1 if is_labels else 0] += 1
        images = [(self._labels if is_labels else self._images).load(i) for i in range(len(self._images))]
        # create lock and get preprocessing function for each image
        image_locks = {}
        image_preprocesses = {}
        for img in images:
            image_locks[img] = threading.Lock()
            image_preprocesses[img] = img.get_preprocess()
            img.set_preprocess(None) # parallelize preprocessing outside lock

        # use same seed for labels and not labels, differ by epoch times big prime number
        rand = random.Random(self._random_seed + epoch * 11617)

        # generator that creates tiles in a random order, but consistent between images and labels
        # returns generator of (img, tile_list) tuples
        def tile_gen():
            image_tiles = [(images[i], self._list_tiles(i)) for i in range(len(images))]
            # shuffle tiles within each image
            for (img, tiles) in image_tiles:
                rand.shuffle(tiles)
            # create iterator
            image_tiles = [(img, iter(tiles)) for (img, tiles) in image_tiles]
            while image_tiles:
                index = rand.randrange(len(image_tiles))
                (img, it) = image_tiles[index]
                try:
                    yield (img, next(it))
                except StopIteration:
                    del image_tiles[index]

        if self._max_rand_offset:
            rand_offset = (rand.randint(-self._max_rand_offset, self._max_rand_offset),
                           rand.randint(-self._max_rand_offset, self._max_rand_offset))
        else:
            rand_offset = (0, 0)
        # lock an image and read it. Necessary because gdal doesn&#39;t do multi-threading.
        def read_image(img, rect):
            lock = image_locks[img]
            preprocess = image_preprocesses[img]
            buf = np.zeros(shape=(img.num_bands(), rect.height(), rect.width()), dtype=img.dtype())

            mod_r = rectangle.Rectangle(min_x=rect.min_x, min_y=rect.min_y, max_x=rect.max_x, max_y=rect.max_y)
            mod_r.shift(rand_offset[0], rand_offset[1])
            request_r = mod_r.get_intersection(rectangle.Rectangle(min_x=0, min_y=0, width=img.width(),
                                                                   height=img.height()))

            lock.acquire()
            partial_buf = buf[:, request_r.min_y - mod_r.min_y:mod_r.height() + request_r.max_y - mod_r.max_y,
                              request_r.min_x - mod_r.min_x:mod_r.width() + request_r.max_x - mod_r.max_x]
            img.read(request_r, buf=partial_buf)
            lock.release()
            # preprocess outside of lock for concurrency
            buf = np.transpose(buf, [1, 2, 0])
            if preprocess:
                buf = preprocess(buf, rect, None)
            return buf

        # add a buffer to read to the multiprocessing queue
        def add_to_queue(buf_queue, item):
            (img, (rect, sub_tiles)) = item
            buf = self._iopool.submit(lambda: read_image(img, rect))
            buf_queue.append((rect, sub_tiles, buf))

        gen = tile_gen()
        buf_queue = []
        for _ in range(config.io.threads() * 2): # add a bit ahead
            try:
                next_item = next(gen)
            except StopIteration:
                break
            add_to_queue(buf_queue, next_item)
        # process buffers and yield sub tiles. For efficiency, we just
        # return an entire buffer&#39;s sub tiles at once, so not fully random
        cur_bufs = []
        while buf_queue or cur_bufs:
            while len(cur_bufs) &lt; config.io.interleave_blocks() and buf_queue:
                (_, sub_tiles, buf) = buf_queue.pop(0)
                cur_bufs.append((sub_tiles, buf.result()))
                try:
                    add_to_queue(buf_queue, next(gen))
                except StopIteration:
                    pass
            while True:
                buf_index = rand.randrange(len(cur_bufs))
                (sub_tiles, buf) = cur_bufs[buf_index]
                if not sub_tiles:
                    del cur_bufs[buf_index]
                    break
                sub_index = rand.randrange(len(sub_tiles))
                s = sub_tiles[sub_index]
                del sub_tiles[sub_index]
                yield buf[s.min_y:s.max_y, s.min_x:s.max_x, :]

    def _load_images(self, is_labels, data_type):
        &#34;&#34;&#34;
        Loads a list of images as tensors.

        Parameters
        ----------
        is_labels: bool
            Load labels if true, images if not
        data_type: numpy.dtype
            Data type that will be returned.

        Returns
        -------
        Dataset:
            Dataset of image tiles
        &#34;&#34;&#34;
        self._epoch[1 if is_labels else 0] = 0 # count epochs for random
        return tf.data.Dataset.from_generator(functools.partial(self._tile_generator,
                                                                is_labels=is_labels),
                                              output_types=data_type,
                                              output_shapes=tf.TensorShape((None, None, None)))

    def _chunk_image(self, image): # pragma: no cover
        &#34;&#34;&#34;Split up a tensor image into tensor chunks&#34;&#34;&#34;

        ksizes  = [1, self._chunk_shape[0], self._chunk_shape[1], 1] # Size of the chunks
        strides = [1, self._stride[0], self._stride[1], 1] # Spacing between chunk starts
        rates   = [1, 1, 1, 1]
        result  = tf.image.extract_patches(tf.expand_dims(image, 0), ksizes, strides, rates,
                                           padding=&#39;VALID&#39;)
        # Output is [1, M, N, chunk*chunk*bands]
        result = tf.reshape(result, [-1, self._chunk_shape[0], self._chunk_shape[1], self._num_bands])

        return result

    def _reshape_labels(self, labels): # pragma: no cover
        &#34;&#34;&#34;Reshape the labels to account for the chunking process.&#34;&#34;&#34;
        if self._chunk_shape:
            h = (self._chunk_shape[0] - self._output_shape[0]) // 2
            w = (self._chunk_shape[1] - self._output_shape[1]) // 2
        else:
            h = (tf.shape(labels)[0] - self._output_shape[0]) // 2
            w = (tf.shape(labels)[1] - self._output_shape[1]) // 2
        labels = tf.image.crop_to_bounding_box(labels, h, w, tf.shape(labels)[0] - 2 * h,
                                               tf.shape(labels)[1] - 2 * w)
        if not self._chunk_shape:
            return labels

        ksizes  = [1, self._output_shape[0], self._output_shape[1], 1]
        strides = [1, self._stride[0], self._stride[1], 1]
        rates   = [1, 1, 1, 1]
        labels = tf.image.extract_patches(tf.expand_dims(labels, 0), ksizes, strides, rates,
                                          padding=&#39;VALID&#39;)
        result = tf.reshape(labels, [-1, self._output_shape[0], self._output_shape[1], 1])
        return result

    def data(self):
        &#34;&#34;&#34;
        Returns
        -------
        Dataset:
            image chunks / tiles.
        &#34;&#34;&#34;
        ret = self._load_images(False, self._data_type)
        if self._chunk_shape:
            ret = ret.map(self._chunk_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            return ret.unbatch()
        return ret

    def labels(self):
        &#34;&#34;&#34;
        Returns
        -------
        Dataset:
            Unbatched dataset of labels corresponding to `data()`.
        &#34;&#34;&#34;
        label_set = self._load_images(True, self._label_type)
        if self._chunk_shape or self._output_shape:
            label_set = label_set.map(self._reshape_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE) #pylint: disable=C0301
            if self._chunk_shape:
                return label_set.unbatch()
        return label_set

    def dataset(self, class_weights=None, augment_function=None):
        &#34;&#34;&#34;
        Returns a tensorflow dataset as configured by the class.

        Parameters
        ----------
        class_weights: list
            list of weights for the classes.
        augment_function: Callable[[Tensor, Tensor], (Tensor, Tensor)]
            Function to be applied to the image and label before use.

        Returns
        -------
        tensorflow Dataset:
            With (data, labels, optionally weights)
        &#34;&#34;&#34;

        # Pair the data and labels in our dataset
        ds = tf.data.Dataset.zip((self.data(), self.labels()))
        # ignore chunks which are all nodata (nodata is re-indexed to be after the classes)
        # cannot do with max_rand_offset since would have different number of tiles which
        # breaks keras fit
        if self._labels.nodata_value() is not None:
            ds = ds.filter(lambda x, y: tf.math.reduce_any(tf.math.not_equal(y, self._labels.nodata_value())))
        if augment_function is not None:
            ds = ds.map(augment_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        if class_weights is not None:
            class_weights.append(0.0)
            lookup = tf.constant(class_weights)
            ds = ds.map(lambda x, y: (x, y, tf.gather(lookup, tf.cast(y, tf.int32), axis=None)),
                        num_parallel_calls=config.io.threads())
        return ds

    def num_bands(self):
        &#34;&#34;&#34;
        Returns
        -------
        int:
            number of bands in each image
        &#34;&#34;&#34;
        return self._num_bands

    def set_chunk_output_shapes(self, chunk_shape, output_shape):
        &#34;&#34;&#34;
        Parameters
        ----------
        chunk_shape: (int, int)
            Size of chunks to read at a time. Set to None to
            use on a per tile basis (i.e., for FCNs).
        output_shape: (int, int)
            Shape output by the network. May differ from the input size
            (dervied from chunk_shape or tile_shape)
        &#34;&#34;&#34;
        if chunk_shape:
            assert len(chunk_shape) == 2, &#39;Chunk must be two dimensional.&#39;
            assert (chunk_shape[0] % 2) == (chunk_shape[1] % 2) == \
                   (output_shape[0] % 2) == (output_shape[1] % 2), &#39;Chunk and output shapes must both be even or odd.&#39;
        if output_shape:
            assert len(output_shape) == 2 or len(output_shape) == 3, &#39;Output must be two or three dimensional.&#39;
            if len(output_shape) == 3:
                output_shape = output_shape[0:2]
        self._chunk_shape = chunk_shape
        self._output_shape = output_shape

    def chunk_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        (int, int):
            Size of chunks used for inputs.
        &#34;&#34;&#34;
        return self._chunk_shape

    def input_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Input size for the network.
        &#34;&#34;&#34;
        if self._chunk_shape:
            return (self._chunk_shape[0], self._chunk_shape[1], self._num_bands)
        return (None, None, self._num_bands)

    def output_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Output size, size of blocks of labels
        &#34;&#34;&#34;
        if self._output_shape:
            return (self._output_shape[0], self._output_shape[1], self._output_dims)
        return (None, None, self._output_dims)

    def image_set(self):
        &#34;&#34;&#34;
        Returns
        -------
        ImageSet:
            set of images
        &#34;&#34;&#34;
        return self._images
    def label_set(self):
        &#34;&#34;&#34;
        Returns
        -------
        ImageSet:
            set of labels
        &#34;&#34;&#34;
        return self._labels

    def set_tile_shape(self, tile_shape):
        &#34;&#34;&#34;
        Set the tile size.

        Parameters
        ----------
        tile_shape: (int, int)
            New tile shape&#34;&#34;&#34;
        self._tile_shape = tile_shape

    def tile_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            tile shape to load at a time
        &#34;&#34;&#34;
        return self._tile_shape

    def tile_overlap(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            the amount tiles overlap
        &#34;&#34;&#34;
        return self._tile_overlap

    def stride(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Stride between chunks (only when chunk_shape is set).
        &#34;&#34;&#34;
        return self._stride

class AutoencoderDataset(ImageryDataset):
    &#34;&#34;&#34;
    Slightly modified dataset class for the autoencoder.

    Instead of specifying labels, the inputs are used as labels.
    &#34;&#34;&#34;

    def __init__(self, images, chunk_shape, stride=(1, 1), tile_shape=(256, 256), tile_overlap=None,
                 max_rand_offset=None):
        super().__init__(images, None, chunk_shape, chunk_shape, tile_shape=tile_shape,
                         stride=stride, tile_overlap=tile_overlap, max_rand_offset=max_rand_offset)
        self._labels = self._images
        self._output_dims = self.num_bands()

    def labels(self):
        return self.data()

    def dataset(self, class_weights=None, augment_function=None):
        return self.data().map(lambda x: (x, x))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="delta.imagery.imagery_dataset.AutoencoderDataset"><code class="flex name class">
<span>class <span class="ident">AutoencoderDataset</span></span>
<span>(</span><span>images, chunk_shape, stride=(1, 1), tile_shape=(256, 256), tile_overlap=None, max_rand_offset=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Slightly modified dataset class for the autoencoder.</p>
<p>Instead of specifying labels, the inputs are used as labels.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>ImageSet</code></dt>
<dd>Images to train on</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>ImageSet</code></dt>
<dd>Corresponding labels to train on</dd>
<dt><strong><code>output_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Shape of the corresponding labels for a given chunk or tile size.</dd>
<dt><strong><code>chunk_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>If specified, divide tiles into individual chunks of this shape.</dd>
<dt><strong><code>stride</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Skip this stride between chunks. Only valid with chunk_shape.</dd>
<dt><strong><code>tile_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Size of tiles to load from the images at a time.</dd>
<dt><strong><code>tile_overlap</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>If specified, overlap tiles by this amount.</dd>
<dt><strong><code>max_rand_offset</code></strong> :&ensp;<code>int</code></dt>
<dd>If specified, in each epoch, offset all tiles by a random amount in x and y
in the range(-max_rand_offset, max_rand_offset).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AutoencoderDataset(ImageryDataset):
    &#34;&#34;&#34;
    Slightly modified dataset class for the autoencoder.

    Instead of specifying labels, the inputs are used as labels.
    &#34;&#34;&#34;

    def __init__(self, images, chunk_shape, stride=(1, 1), tile_shape=(256, 256), tile_overlap=None,
                 max_rand_offset=None):
        super().__init__(images, None, chunk_shape, chunk_shape, tile_shape=tile_shape,
                         stride=stride, tile_overlap=tile_overlap, max_rand_offset=max_rand_offset)
        self._labels = self._images
        self._output_dims = self.num_bands()

    def labels(self):
        return self.data()

    def dataset(self, class_weights=None, augment_function=None):
        return self.data().map(lambda x: (x, x))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="delta.imagery.imagery_dataset.ImageryDataset" href="#delta.imagery.imagery_dataset.ImageryDataset">ImageryDataset</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="delta.imagery.imagery_dataset.ImageryDataset" href="#delta.imagery.imagery_dataset.ImageryDataset">ImageryDataset</a></b></code>:
<ul class="hlist">
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.chunk_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.chunk_shape">chunk_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.data" href="#delta.imagery.imagery_dataset.ImageryDataset.data">data</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.dataset" href="#delta.imagery.imagery_dataset.ImageryDataset.dataset">dataset</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.image_set" href="#delta.imagery.imagery_dataset.ImageryDataset.image_set">image_set</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.input_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.input_shape">input_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.label_set" href="#delta.imagery.imagery_dataset.ImageryDataset.label_set">label_set</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.labels" href="#delta.imagery.imagery_dataset.ImageryDataset.labels">labels</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.num_bands" href="#delta.imagery.imagery_dataset.ImageryDataset.num_bands">num_bands</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.output_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.output_shape">output_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.set_chunk_output_shapes" href="#delta.imagery.imagery_dataset.ImageryDataset.set_chunk_output_shapes">set_chunk_output_shapes</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.set_tile_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.set_tile_shape">set_tile_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.stride" href="#delta.imagery.imagery_dataset.ImageryDataset.stride">stride</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.tile_overlap" href="#delta.imagery.imagery_dataset.ImageryDataset.tile_overlap">tile_overlap</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.tile_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.tile_shape">tile_shape</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset"><code class="flex name class">
<span>class <span class="ident">ImageryDataset</span></span>
<span>(</span><span>images, labels, output_shape, chunk_shape, stride=None, tile_shape=(256, 256), tile_overlap=None, max_rand_offset=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A dataset for tiling very large imagery for training with tensorflow.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>ImageSet</code></dt>
<dd>Images to train on</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>ImageSet</code></dt>
<dd>Corresponding labels to train on</dd>
<dt><strong><code>output_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Shape of the corresponding labels for a given chunk or tile size.</dd>
<dt><strong><code>chunk_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>If specified, divide tiles into individual chunks of this shape.</dd>
<dt><strong><code>stride</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Skip this stride between chunks. Only valid with chunk_shape.</dd>
<dt><strong><code>tile_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Size of tiles to load from the images at a time.</dd>
<dt><strong><code>tile_overlap</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>If specified, overlap tiles by this amount.</dd>
<dt><strong><code>max_rand_offset</code></strong> :&ensp;<code>int</code></dt>
<dd>If specified, in each epoch, offset all tiles by a random amount in x and y
in the range(-max_rand_offset, max_rand_offset).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImageryDataset: # pylint: disable=too-many-instance-attributes,too-many-arguments
    &#34;&#34;&#34;
    A dataset for tiling very large imagery for training with tensorflow.
    &#34;&#34;&#34;

    def __init__(self, images, labels, output_shape, chunk_shape, stride=None,
                 tile_shape=(256, 256), tile_overlap=None, max_rand_offset=None):
        &#34;&#34;&#34;
        Parameters
        ----------
        images: ImageSet
            Images to train on
        labels: ImageSet
            Corresponding labels to train on
        output_shape: (int, int)
            Shape of the corresponding labels for a given chunk or tile size.
        chunk_shape: (int, int)
            If specified, divide tiles into individual chunks of this shape.
        stride: (int, int)
            Skip this stride between chunks. Only valid with chunk_shape.
        tile_shape: (int, int)
            Size of tiles to load from the images at a time.
        tile_overlap: (int, int)
            If specified, overlap tiles by this amount.
        max_rand_offset: int
            If specified, in each epoch, offset all tiles by a random amount in x and y
            in the range(-max_rand_offset, max_rand_offset).
        &#34;&#34;&#34;

        self._iopool = ThreadPoolExecutor(config.io.threads())

        # Record some of the config values
        self.set_chunk_output_shapes(chunk_shape, output_shape)
        self._output_dims  = 1
        # one for imagery, one for labels
        if stride is None:
            stride = (1, 1)
        self._stride = stride
        self._data_type    = tf.float32
        self._label_type   = tf.uint8
        self._tile_shape = tile_shape
        if tile_overlap is None:
            tile_overlap = (0, 0)
        self._tile_overlap = tile_overlap
        self._max_rand_offset = max_rand_offset if max_rand_offset else 0

        if labels:
            assert len(images) == len(labels)
        self._images = images
        self._labels = labels
        self._epoch = [0, 0] # track images and labels separately for simplicity

        # Load the first image to get the number of bands for the input files.
        self._num_bands = images.load(0).num_bands()
        self._random_seed = random.randint(0, 1 &lt;&lt; 16)

    def _list_tiles(self, i): # pragma: no cover
        &#34;&#34;&#34;
        Parameters
        ----------
        i: int
            Image to list tiles for.

        Returns
        -------
        List[Rectangle]:
            List of tiles to read from the given image
        &#34;&#34;&#34;
        img = self._images.load(i)

        if self._labels: # If we have labels make sure they are the same size as the input images
            label = self._labels.load(i)
            if label.size() != img.size():
                raise AssertionError(&#39;Label file &#39; + self._labels[i] + &#39; with size &#39; + str(label.size())
                                     + &#39; does not match input image &#39; + self._images[i] + &#39; size of &#39; + str(img.size()))
        tile_shape = self._tile_shape
        if self._chunk_shape:
            assert tile_shape[0] &gt;= self._chunk_shape[0] and \
                   tile_shape[1] &gt;= self._chunk_shape[1], &#39;Tile too small.&#39;
            return img.tiles((tile_shape[0], tile_shape[1]), min_shape=self._chunk_shape,
                             overlap_shape=self._tile_overlap,
                             by_block=True)
        return img.tiles((tile_shape[0], tile_shape[1]), partials=False, partials_overlap=True,
                         overlap_shape=self._tile_overlap, by_block=True)

    def _tile_generator(self, is_labels): # pragma: no cover
        &#34;&#34;&#34;
        A generator that yields image tiles over all images.

        Parameters
        ----------
        is_labels: bool
            Load the label if true, image if false

        Returns
        -------
        Iterator[numpy.ndarray]:
            Iterator over iamge tiles.
        &#34;&#34;&#34;
        # track epoch (must be same for label and non-label)
        epoch = self._epoch[1 if is_labels else 0]
        self._epoch[1 if is_labels else 0] += 1
        images = [(self._labels if is_labels else self._images).load(i) for i in range(len(self._images))]
        # create lock and get preprocessing function for each image
        image_locks = {}
        image_preprocesses = {}
        for img in images:
            image_locks[img] = threading.Lock()
            image_preprocesses[img] = img.get_preprocess()
            img.set_preprocess(None) # parallelize preprocessing outside lock

        # use same seed for labels and not labels, differ by epoch times big prime number
        rand = random.Random(self._random_seed + epoch * 11617)

        # generator that creates tiles in a random order, but consistent between images and labels
        # returns generator of (img, tile_list) tuples
        def tile_gen():
            image_tiles = [(images[i], self._list_tiles(i)) for i in range(len(images))]
            # shuffle tiles within each image
            for (img, tiles) in image_tiles:
                rand.shuffle(tiles)
            # create iterator
            image_tiles = [(img, iter(tiles)) for (img, tiles) in image_tiles]
            while image_tiles:
                index = rand.randrange(len(image_tiles))
                (img, it) = image_tiles[index]
                try:
                    yield (img, next(it))
                except StopIteration:
                    del image_tiles[index]

        if self._max_rand_offset:
            rand_offset = (rand.randint(-self._max_rand_offset, self._max_rand_offset),
                           rand.randint(-self._max_rand_offset, self._max_rand_offset))
        else:
            rand_offset = (0, 0)
        # lock an image and read it. Necessary because gdal doesn&#39;t do multi-threading.
        def read_image(img, rect):
            lock = image_locks[img]
            preprocess = image_preprocesses[img]
            buf = np.zeros(shape=(img.num_bands(), rect.height(), rect.width()), dtype=img.dtype())

            mod_r = rectangle.Rectangle(min_x=rect.min_x, min_y=rect.min_y, max_x=rect.max_x, max_y=rect.max_y)
            mod_r.shift(rand_offset[0], rand_offset[1])
            request_r = mod_r.get_intersection(rectangle.Rectangle(min_x=0, min_y=0, width=img.width(),
                                                                   height=img.height()))

            lock.acquire()
            partial_buf = buf[:, request_r.min_y - mod_r.min_y:mod_r.height() + request_r.max_y - mod_r.max_y,
                              request_r.min_x - mod_r.min_x:mod_r.width() + request_r.max_x - mod_r.max_x]
            img.read(request_r, buf=partial_buf)
            lock.release()
            # preprocess outside of lock for concurrency
            buf = np.transpose(buf, [1, 2, 0])
            if preprocess:
                buf = preprocess(buf, rect, None)
            return buf

        # add a buffer to read to the multiprocessing queue
        def add_to_queue(buf_queue, item):
            (img, (rect, sub_tiles)) = item
            buf = self._iopool.submit(lambda: read_image(img, rect))
            buf_queue.append((rect, sub_tiles, buf))

        gen = tile_gen()
        buf_queue = []
        for _ in range(config.io.threads() * 2): # add a bit ahead
            try:
                next_item = next(gen)
            except StopIteration:
                break
            add_to_queue(buf_queue, next_item)
        # process buffers and yield sub tiles. For efficiency, we just
        # return an entire buffer&#39;s sub tiles at once, so not fully random
        cur_bufs = []
        while buf_queue or cur_bufs:
            while len(cur_bufs) &lt; config.io.interleave_blocks() and buf_queue:
                (_, sub_tiles, buf) = buf_queue.pop(0)
                cur_bufs.append((sub_tiles, buf.result()))
                try:
                    add_to_queue(buf_queue, next(gen))
                except StopIteration:
                    pass
            while True:
                buf_index = rand.randrange(len(cur_bufs))
                (sub_tiles, buf) = cur_bufs[buf_index]
                if not sub_tiles:
                    del cur_bufs[buf_index]
                    break
                sub_index = rand.randrange(len(sub_tiles))
                s = sub_tiles[sub_index]
                del sub_tiles[sub_index]
                yield buf[s.min_y:s.max_y, s.min_x:s.max_x, :]

    def _load_images(self, is_labels, data_type):
        &#34;&#34;&#34;
        Loads a list of images as tensors.

        Parameters
        ----------
        is_labels: bool
            Load labels if true, images if not
        data_type: numpy.dtype
            Data type that will be returned.

        Returns
        -------
        Dataset:
            Dataset of image tiles
        &#34;&#34;&#34;
        self._epoch[1 if is_labels else 0] = 0 # count epochs for random
        return tf.data.Dataset.from_generator(functools.partial(self._tile_generator,
                                                                is_labels=is_labels),
                                              output_types=data_type,
                                              output_shapes=tf.TensorShape((None, None, None)))

    def _chunk_image(self, image): # pragma: no cover
        &#34;&#34;&#34;Split up a tensor image into tensor chunks&#34;&#34;&#34;

        ksizes  = [1, self._chunk_shape[0], self._chunk_shape[1], 1] # Size of the chunks
        strides = [1, self._stride[0], self._stride[1], 1] # Spacing between chunk starts
        rates   = [1, 1, 1, 1]
        result  = tf.image.extract_patches(tf.expand_dims(image, 0), ksizes, strides, rates,
                                           padding=&#39;VALID&#39;)
        # Output is [1, M, N, chunk*chunk*bands]
        result = tf.reshape(result, [-1, self._chunk_shape[0], self._chunk_shape[1], self._num_bands])

        return result

    def _reshape_labels(self, labels): # pragma: no cover
        &#34;&#34;&#34;Reshape the labels to account for the chunking process.&#34;&#34;&#34;
        if self._chunk_shape:
            h = (self._chunk_shape[0] - self._output_shape[0]) // 2
            w = (self._chunk_shape[1] - self._output_shape[1]) // 2
        else:
            h = (tf.shape(labels)[0] - self._output_shape[0]) // 2
            w = (tf.shape(labels)[1] - self._output_shape[1]) // 2
        labels = tf.image.crop_to_bounding_box(labels, h, w, tf.shape(labels)[0] - 2 * h,
                                               tf.shape(labels)[1] - 2 * w)
        if not self._chunk_shape:
            return labels

        ksizes  = [1, self._output_shape[0], self._output_shape[1], 1]
        strides = [1, self._stride[0], self._stride[1], 1]
        rates   = [1, 1, 1, 1]
        labels = tf.image.extract_patches(tf.expand_dims(labels, 0), ksizes, strides, rates,
                                          padding=&#39;VALID&#39;)
        result = tf.reshape(labels, [-1, self._output_shape[0], self._output_shape[1], 1])
        return result

    def data(self):
        &#34;&#34;&#34;
        Returns
        -------
        Dataset:
            image chunks / tiles.
        &#34;&#34;&#34;
        ret = self._load_images(False, self._data_type)
        if self._chunk_shape:
            ret = ret.map(self._chunk_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
            return ret.unbatch()
        return ret

    def labels(self):
        &#34;&#34;&#34;
        Returns
        -------
        Dataset:
            Unbatched dataset of labels corresponding to `data()`.
        &#34;&#34;&#34;
        label_set = self._load_images(True, self._label_type)
        if self._chunk_shape or self._output_shape:
            label_set = label_set.map(self._reshape_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE) #pylint: disable=C0301
            if self._chunk_shape:
                return label_set.unbatch()
        return label_set

    def dataset(self, class_weights=None, augment_function=None):
        &#34;&#34;&#34;
        Returns a tensorflow dataset as configured by the class.

        Parameters
        ----------
        class_weights: list
            list of weights for the classes.
        augment_function: Callable[[Tensor, Tensor], (Tensor, Tensor)]
            Function to be applied to the image and label before use.

        Returns
        -------
        tensorflow Dataset:
            With (data, labels, optionally weights)
        &#34;&#34;&#34;

        # Pair the data and labels in our dataset
        ds = tf.data.Dataset.zip((self.data(), self.labels()))
        # ignore chunks which are all nodata (nodata is re-indexed to be after the classes)
        # cannot do with max_rand_offset since would have different number of tiles which
        # breaks keras fit
        if self._labels.nodata_value() is not None:
            ds = ds.filter(lambda x, y: tf.math.reduce_any(tf.math.not_equal(y, self._labels.nodata_value())))
        if augment_function is not None:
            ds = ds.map(augment_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        if class_weights is not None:
            class_weights.append(0.0)
            lookup = tf.constant(class_weights)
            ds = ds.map(lambda x, y: (x, y, tf.gather(lookup, tf.cast(y, tf.int32), axis=None)),
                        num_parallel_calls=config.io.threads())
        return ds

    def num_bands(self):
        &#34;&#34;&#34;
        Returns
        -------
        int:
            number of bands in each image
        &#34;&#34;&#34;
        return self._num_bands

    def set_chunk_output_shapes(self, chunk_shape, output_shape):
        &#34;&#34;&#34;
        Parameters
        ----------
        chunk_shape: (int, int)
            Size of chunks to read at a time. Set to None to
            use on a per tile basis (i.e., for FCNs).
        output_shape: (int, int)
            Shape output by the network. May differ from the input size
            (dervied from chunk_shape or tile_shape)
        &#34;&#34;&#34;
        if chunk_shape:
            assert len(chunk_shape) == 2, &#39;Chunk must be two dimensional.&#39;
            assert (chunk_shape[0] % 2) == (chunk_shape[1] % 2) == \
                   (output_shape[0] % 2) == (output_shape[1] % 2), &#39;Chunk and output shapes must both be even or odd.&#39;
        if output_shape:
            assert len(output_shape) == 2 or len(output_shape) == 3, &#39;Output must be two or three dimensional.&#39;
            if len(output_shape) == 3:
                output_shape = output_shape[0:2]
        self._chunk_shape = chunk_shape
        self._output_shape = output_shape

    def chunk_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        (int, int):
            Size of chunks used for inputs.
        &#34;&#34;&#34;
        return self._chunk_shape

    def input_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Input size for the network.
        &#34;&#34;&#34;
        if self._chunk_shape:
            return (self._chunk_shape[0], self._chunk_shape[1], self._num_bands)
        return (None, None, self._num_bands)

    def output_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Output size, size of blocks of labels
        &#34;&#34;&#34;
        if self._output_shape:
            return (self._output_shape[0], self._output_shape[1], self._output_dims)
        return (None, None, self._output_dims)

    def image_set(self):
        &#34;&#34;&#34;
        Returns
        -------
        ImageSet:
            set of images
        &#34;&#34;&#34;
        return self._images
    def label_set(self):
        &#34;&#34;&#34;
        Returns
        -------
        ImageSet:
            set of labels
        &#34;&#34;&#34;
        return self._labels

    def set_tile_shape(self, tile_shape):
        &#34;&#34;&#34;
        Set the tile size.

        Parameters
        ----------
        tile_shape: (int, int)
            New tile shape&#34;&#34;&#34;
        self._tile_shape = tile_shape

    def tile_shape(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            tile shape to load at a time
        &#34;&#34;&#34;
        return self._tile_shape

    def tile_overlap(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            the amount tiles overlap
        &#34;&#34;&#34;
        return self._tile_overlap

    def stride(self):
        &#34;&#34;&#34;
        Returns
        -------
        Tuple[int, ...]:
            Stride between chunks (only when chunk_shape is set).
        &#34;&#34;&#34;
        return self._stride</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="delta.imagery.imagery_dataset.AutoencoderDataset" href="#delta.imagery.imagery_dataset.AutoencoderDataset">AutoencoderDataset</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.chunk_shape"><code class="name flex">
<span>def <span class="ident">chunk_shape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<p>(int, int):
Size of chunks used for inputs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chunk_shape(self):
    &#34;&#34;&#34;
    Returns
    -------
    (int, int):
        Size of chunks used for inputs.
    &#34;&#34;&#34;
    return self._chunk_shape</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.data"><code class="name flex">
<span>def <span class="ident">data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<h2 id="dataset">Dataset</h2>
<p>image chunks / tiles.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data(self):
    &#34;&#34;&#34;
    Returns
    -------
    Dataset:
        image chunks / tiles.
    &#34;&#34;&#34;
    ret = self._load_images(False, self._data_type)
    if self._chunk_shape:
        ret = ret.map(self._chunk_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        return ret.unbatch()
    return ret</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.dataset"><code class="name flex">
<span>def <span class="ident">dataset</span></span>(<span>self, class_weights=None, augment_function=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a tensorflow dataset as configured by the class.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>class_weights</code></strong> :&ensp;<code>list</code></dt>
<dd>list of weights for the classes.</dd>
<dt><strong><code>augment_function</code></strong> :&ensp;<code>Callable[[Tensor, Tensor], (Tensor, Tensor)]</code></dt>
<dd>Function to be applied to the image and label before use.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tensorflow Dataset:</code></dt>
<dd>With (data, labels, optionally weights)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dataset(self, class_weights=None, augment_function=None):
    &#34;&#34;&#34;
    Returns a tensorflow dataset as configured by the class.

    Parameters
    ----------
    class_weights: list
        list of weights for the classes.
    augment_function: Callable[[Tensor, Tensor], (Tensor, Tensor)]
        Function to be applied to the image and label before use.

    Returns
    -------
    tensorflow Dataset:
        With (data, labels, optionally weights)
    &#34;&#34;&#34;

    # Pair the data and labels in our dataset
    ds = tf.data.Dataset.zip((self.data(), self.labels()))
    # ignore chunks which are all nodata (nodata is re-indexed to be after the classes)
    # cannot do with max_rand_offset since would have different number of tiles which
    # breaks keras fit
    if self._labels.nodata_value() is not None:
        ds = ds.filter(lambda x, y: tf.math.reduce_any(tf.math.not_equal(y, self._labels.nodata_value())))
    if augment_function is not None:
        ds = ds.map(augment_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    if class_weights is not None:
        class_weights.append(0.0)
        lookup = tf.constant(class_weights)
        ds = ds.map(lambda x, y: (x, y, tf.gather(lookup, tf.cast(y, tf.int32), axis=None)),
                    num_parallel_calls=config.io.threads())
    return ds</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.image_set"><code class="name flex">
<span>def <span class="ident">image_set</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<h2 id="imageset">Imageset</h2>
<p>set of images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def image_set(self):
    &#34;&#34;&#34;
    Returns
    -------
    ImageSet:
        set of images
    &#34;&#34;&#34;
    return self._images</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.input_shape"><code class="name flex">
<span>def <span class="ident">input_shape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, ...]:</code></dt>
<dd>Input size for the network.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def input_shape(self):
    &#34;&#34;&#34;
    Returns
    -------
    Tuple[int, ...]:
        Input size for the network.
    &#34;&#34;&#34;
    if self._chunk_shape:
        return (self._chunk_shape[0], self._chunk_shape[1], self._num_bands)
    return (None, None, self._num_bands)</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.label_set"><code class="name flex">
<span>def <span class="ident">label_set</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<h2 id="imageset">Imageset</h2>
<p>set of labels</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def label_set(self):
    &#34;&#34;&#34;
    Returns
    -------
    ImageSet:
        set of labels
    &#34;&#34;&#34;
    return self._labels</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.labels"><code class="name flex">
<span>def <span class="ident">labels</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<h2 id="dataset">Dataset</h2>
<p>Unbatched dataset of labels corresponding to <code>data()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def labels(self):
    &#34;&#34;&#34;
    Returns
    -------
    Dataset:
        Unbatched dataset of labels corresponding to `data()`.
    &#34;&#34;&#34;
    label_set = self._load_images(True, self._label_type)
    if self._chunk_shape or self._output_shape:
        label_set = label_set.map(self._reshape_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE) #pylint: disable=C0301
        if self._chunk_shape:
            return label_set.unbatch()
    return label_set</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.num_bands"><code class="name flex">
<span>def <span class="ident">num_bands</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>int:</code></dt>
<dd>number of bands in each image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def num_bands(self):
    &#34;&#34;&#34;
    Returns
    -------
    int:
        number of bands in each image
    &#34;&#34;&#34;
    return self._num_bands</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.output_shape"><code class="name flex">
<span>def <span class="ident">output_shape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, ...]:</code></dt>
<dd>Output size, size of blocks of labels</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def output_shape(self):
    &#34;&#34;&#34;
    Returns
    -------
    Tuple[int, ...]:
        Output size, size of blocks of labels
    &#34;&#34;&#34;
    if self._output_shape:
        return (self._output_shape[0], self._output_shape[1], self._output_dims)
    return (None, None, self._output_dims)</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.set_chunk_output_shapes"><code class="name flex">
<span>def <span class="ident">set_chunk_output_shapes</span></span>(<span>self, chunk_shape, output_shape)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>chunk_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Size of chunks to read at a time. Set to None to
use on a per tile basis (i.e., for FCNs).</dd>
<dt><strong><code>output_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>Shape output by the network. May differ from the input size
(dervied from chunk_shape or tile_shape)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_chunk_output_shapes(self, chunk_shape, output_shape):
    &#34;&#34;&#34;
    Parameters
    ----------
    chunk_shape: (int, int)
        Size of chunks to read at a time. Set to None to
        use on a per tile basis (i.e., for FCNs).
    output_shape: (int, int)
        Shape output by the network. May differ from the input size
        (dervied from chunk_shape or tile_shape)
    &#34;&#34;&#34;
    if chunk_shape:
        assert len(chunk_shape) == 2, &#39;Chunk must be two dimensional.&#39;
        assert (chunk_shape[0] % 2) == (chunk_shape[1] % 2) == \
               (output_shape[0] % 2) == (output_shape[1] % 2), &#39;Chunk and output shapes must both be even or odd.&#39;
    if output_shape:
        assert len(output_shape) == 2 or len(output_shape) == 3, &#39;Output must be two or three dimensional.&#39;
        if len(output_shape) == 3:
            output_shape = output_shape[0:2]
    self._chunk_shape = chunk_shape
    self._output_shape = output_shape</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.set_tile_shape"><code class="name flex">
<span>def <span class="ident">set_tile_shape</span></span>(<span>self, tile_shape)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the tile size.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tile_shape</code></strong> :&ensp;<code>(int, int)</code></dt>
<dd>New tile shape</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_tile_shape(self, tile_shape):
    &#34;&#34;&#34;
    Set the tile size.

    Parameters
    ----------
    tile_shape: (int, int)
        New tile shape&#34;&#34;&#34;
    self._tile_shape = tile_shape</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.stride"><code class="name flex">
<span>def <span class="ident">stride</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, ...]:</code></dt>
<dd>Stride between chunks (only when chunk_shape is set).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stride(self):
    &#34;&#34;&#34;
    Returns
    -------
    Tuple[int, ...]:
        Stride between chunks (only when chunk_shape is set).
    &#34;&#34;&#34;
    return self._stride</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.tile_overlap"><code class="name flex">
<span>def <span class="ident">tile_overlap</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, ...]:</code></dt>
<dd>the amount tiles overlap</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tile_overlap(self):
    &#34;&#34;&#34;
    Returns
    -------
    Tuple[int, ...]:
        the amount tiles overlap
    &#34;&#34;&#34;
    return self._tile_overlap</code></pre>
</details>
</dd>
<dt id="delta.imagery.imagery_dataset.ImageryDataset.tile_shape"><code class="name flex">
<span>def <span class="ident">tile_shape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, ...]:</code></dt>
<dd>tile shape to load at a time</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tile_shape(self):
    &#34;&#34;&#34;
    Returns
    -------
    Tuple[int, ...]:
        tile shape to load at a time
    &#34;&#34;&#34;
    return self._tile_shape</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="delta.imagery" href="index.html">delta.imagery</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="delta.imagery.imagery_dataset.AutoencoderDataset" href="#delta.imagery.imagery_dataset.AutoencoderDataset">AutoencoderDataset</a></code></h4>
</li>
<li>
<h4><code><a title="delta.imagery.imagery_dataset.ImageryDataset" href="#delta.imagery.imagery_dataset.ImageryDataset">ImageryDataset</a></code></h4>
<ul class="">
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.chunk_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.chunk_shape">chunk_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.data" href="#delta.imagery.imagery_dataset.ImageryDataset.data">data</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.dataset" href="#delta.imagery.imagery_dataset.ImageryDataset.dataset">dataset</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.image_set" href="#delta.imagery.imagery_dataset.ImageryDataset.image_set">image_set</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.input_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.input_shape">input_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.label_set" href="#delta.imagery.imagery_dataset.ImageryDataset.label_set">label_set</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.labels" href="#delta.imagery.imagery_dataset.ImageryDataset.labels">labels</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.num_bands" href="#delta.imagery.imagery_dataset.ImageryDataset.num_bands">num_bands</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.output_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.output_shape">output_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.set_chunk_output_shapes" href="#delta.imagery.imagery_dataset.ImageryDataset.set_chunk_output_shapes">set_chunk_output_shapes</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.set_tile_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.set_tile_shape">set_tile_shape</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.stride" href="#delta.imagery.imagery_dataset.ImageryDataset.stride">stride</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.tile_overlap" href="#delta.imagery.imagery_dataset.ImageryDataset.tile_overlap">tile_overlap</a></code></li>
<li><code><a title="delta.imagery.imagery_dataset.ImageryDataset.tile_shape" href="#delta.imagery.imagery_dataset.ImageryDataset.tile_shape">tile_shape</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>